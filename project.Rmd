---
title: "ST309_Project"
author: "Paxton Quek, Patricia Yin"
date: "02/02/2021"
output: pdf_document
---

# I. Exploratory Analysis
## 1. Load Data
```{r}
#setwd("~/Documents/好好学习！/R/ST309/st309-project")
library(tidyverse)
library(car)
library(ggplot2)
library(readxl)
library(stringr)
library(rgdal)
library(dplyr)
library(data.table)

listings1 <- read_excel("9Dec2019_PriceAmenitiesRatings.xlsx")
listings_o <- read_excel("9Dec2019_PriceAmenitiesRatings.xlsx")
summary(listings1)
```

## 2. Price
```{r}

# Standardise all cleaning_fee such that entries with "NA" are 0 
listings1$cleaning_fee[is.na(listings1$cleaning_fee)]=0

# Add a new column with normalised prices (pro-rata per person for a 3-day stay)
# this is to account for the cleaning_fee, which can be substantial
listings1$price_n <- with(listings1,(price*3 + cleaning_fee)/3/guests_included)



```

## 3. host_since
```{r}
#host_since 
host_since_n <- listings1$host_since

#change host_since to years of operating, round up/down to nearest year
host_since_n <- as.numeric(round((as.Date("2020-02-08", format = "%Y-%m-%d") - as.Date(host_since_n, format = "%Y-%m-%d"))/365))

listings1$host_since_n <- host_since_n
```

## 4. host_response_time
```{r}
host_response_time_n <- as.factor(listings1$host_response_time)
#combine NA and N/A as N/A because this level might be significant in further analysis.
host_response_time_n[is.na(host_response_time_n)] <- "N/A"
listings1$host_response_time_n <- host_response_time_n
```

## 5. host_response_rate
```{r}
host_response_rate_n <- as.numeric(listings1$host_response_rate)
hist(host_response_rate_n)
summary(host_response_rate_n)
#recode the variable as factor: 100% is one level, not 100% another, NA the third
host_response_rate_n[host_response_rate_n != 1] <- "Not100"
host_response_rate_n[host_response_rate_n == 1] <- "100"
host_response_rate_n[is.na(host_response_rate_n)] <- "N/A"
host_response_rate_n <- as.factor(host_response_rate_n)
listings1$host_response_rate_n <- host_response_rate_n
```

## 6. host_is_superhost
```{r}
summary(as.factor(listings1$host_is_superhost))
#note that host_response_time has 944 NA, host_response_rate has 944 NA, host_is_superhost has 944 NA, investigation below
```

## 7. 944 entries w zero data for host

```{r}
#investigate:
compare_1 <- listings_o$id[is.na(listings_o$host_response_time)] == listings_o$id[is.na(listings_o$host_response_rate)]
length(compare_1[compare_1 == FALSE])
compare_2 <- listings_o$id[is.na(listings_o$host_response_rate)] == listings_o$id[is.na(listings_o$host_is_superhost)]
length(compare_2[compare_2 == FALSE])
#it is the same listings which has NA for all three columns
host_NA.dat <- subset(listings_o, is.na(host_response_rate))
head(host_NA.dat)
sample(host_NA.dat$id, size =3)
#remove the 944 entries
listings1 <- listings1[!is.na(listings1$host_since),]

```

By randomly checking five of the listings, the information about host is actually available on Airbnb. We believe the NA in the dataset might be due to some technical issues. Removing them from the dataset will not introduce significant bias. 

## 8. host verification

```{r}
host_vn <- listings1$host_verifications

#convert empty entry in host_verification to NA & save NA rows numbers
NArows <- c()
for (i in 1:length(host_vn)) {
  if (host_vn[i] == "[]") {
    host_vn[i] = NA
    NArows <- c(NArows, i)
  }
}

#split word entries in the host_verification
host_vnList <- strsplit(host_vn, split =",")

#clean host_vn by removing the signs 
remove.sign <- function (df) {
  str_replace_all(df, "[^[:alnum:]]", "")
  }
host_vnClean <- lapply(host_vnList, remove.sign)

#code the name of each list in the list of lists using their rownumber
names(host_vnClean) <- 1:length(host_vnClean)
#this is a precaution to deal with messed up row numbers after removing NAs

#get a list of all possible methods
getAllMethods <- function (LOL) {
  methods <- c()
  checks <- c()
  for (i in 1:length(LOL)) {
    for (j in 1:length(LOL[[i]])) {
      if (!(LOL[[i]][j] %in% methods)) {
        methods <- c(methods, LOL[[i]][j])
      }
    }
  }
  return(methods)
}

#NA is removed from the verification methods list
methods <- getAllMethods(host_vnClean)[1:20]


#take each method as a dimension, recode host_vnClean to a list of vectors
host_vnNew = matrix(0, ncol = length(methods),nrow = length(host_vnClean))
colnames(host_vnNew) <- methods

for (i in 1:length(host_vnClean)) {
  for (m in 1:length(methods)) {
    if (methods[m] %in% host_vnClean[[i]]) {
      host_vnNew[i,m] <- 1
    }
  }
}

#perform kmeans clustering
km.out <- kmeans(host_vnNew, 4, nstart = 100)
kmeans_results <- km.out$cluster
kmeans_centroids <- km.out$centers
for (i in 1:4) {print(length(which(cluster_results == i)))}

listings1$host_verification_n <- kmeans_results
```

## 9. street

```{r}
street_n <- as.factor(listings1$street)
summary(street_n)
#many do not have an exact street name, not considered further.
```

## 10. neighbourhood_cleansed

```{r}
neig_n <- as.factor(listings1$neighbourhood_cleansed)
summary(neig_n)
# no interesting transformation to think of
```

## 11. latitude and longitude

```{r}
lis_location <- listings1[c("zipcode", "latitude", "longitude")]
summary(lis_location)

#load the shapefile of london boroughs
ldn_boroughs <- readOGR(dsn = "London-boroughs/London_Borough_Excluding_MHW.shp") #the whole london-boroughs folder must be downloaded because .shp (shapefile) is composed by different files in the folder.
#transform the coordinates to longitude and latitude
proj4string(ldn_boroughs) <- CRS("+init=epsg:27700")
ldn_boroughs.wgs84 <- spTransform(ldn_boroughs, CRS("+init=epsg:4326"))

#plot map with listings data
map1 <- ggplot() + geom_polygon(data=ldn_boroughs.wgs84, mapping=aes(long, lat, group = group, fill = group)) + geom_path(data=ldn_boroughs.wgs84, mapping=aes(long, lat, group = group), color="white", lwd=0.1)
#map1 <- ggplot() + geom_polygon(data=ldn_boroughs.wgs84, mapping=aes(long, lat, group = group), fill="dimgrey") + geom_path(data=ldn_boroughs.wgs84, mapping=aes(long, lat, group = group), color="white", lwd=0.1)
map2 <- map1 + geom_point(data=lis_location, mapping=aes(longitude, latitude), color = "dimgrey", size=0.05) + ggtitle("Airbnb listings in London") + theme(legend.position = "none")

#transform location data to distance to central london
cent_ldn_lat <- 51.509865
cent_ldn_long <- -0.118092

mil_to_centre_n <- sqrt(((lis_location$longitude - cent_ldn_long)*54.6)^2 + ((lis_location$latitude - cent_ldn_lat)*69)^2)
summary(mil_to_centre_n)

listings1$mil_to_centre_n <- mil_to_centre_n
```

[1]  https://toboroughsdatascience.com/plotting-a-map-of-london-crime-data-using-r-8dcefef1c397 the reference for transformation of coordinates to longitude and latitude
[2]  https://www.latlong.net/place/london-the-uk-14153.html centre of london longitude and latitude

## 12. is_location_exact
```{r}
listings1$is_location_exact <- summary(as.factor(listings1$is_location_exact))
```

## 13. property
```{r}
#group the more expensive properties as one level
summary(as.factor(listings1$property_type))
```

## 14. room types

```{r}
summary(as.factor(listings1$room_type))
listings1$room_type <- as.factor(listings1$room_type)
```


## 15. bed types

```{r}
summary(as.factor(listings1$bed_type))
#change to real bed and non real bed as other categories have too few data
bed_type_n <- listings1$bed_type
bed_type_n[bed_type_n != "Real Bed"] <- "Non Bed"
summary(as.factor(bed_type_n))
listings1$bed_type_n <- as.factor(bed_type_n)
```

## 16. amenities

```{r}
amenities_n <- listings1$amenities
head(amenities_n)
amenities_list <- strsplit(amenities_n, ",")
head(amenities_list)
#clean amenities list
remove.punc <- function(mylist) {str_remove_all(mylist, "[:punct:]")}
a_clean_list <- lapply(amenities_list, remove.punc)
#find all possible items provided
raw_items <- getAllMethods(a_clean_list)

getMethodFreq <- function (LOL, item_list){
  
  freq_list <- matrix(0, nrow = length(item_list), ncol = 1)
  rownames(freq_list) <- item_list
  colnames(freq_list) <- "freq"
  
  for (m in 1:length(item_list)) {
    count = 0
    for (i in 1:length(LOL)) {
      if (item_list[m] %in% LOL[[i]]) {
        count = count + 1
      }
    freq_list[m][1] = count
    }
  }
  return (freq_list)
}

#get the frequency that each item appears
item_freq <- getMethodFreq(a_clean_list, raw_items)

item_freq <- as.data.frame(item_freq)
item_freq <- rownames_to_column(item_freq, "item")
item_freq <- item_freq[order(item_freq$freq, decreasing = T),]


as.data.frame(a[order(a, decreasing =T),])
#some attempts
a_clean_sam <- a_clean_list[1:10]

items

unlist(amenities_list[[6]])
str_extract_all(amenities_list[[6]], "\\\".+")

```







# II. Data Analysis