---
title: "ST309_Project"
author: "Paxton Quek, Patricia Yin"
date: "02/02/2021"
output: pdf_document
---

# I. Exploratory Analysis
## 1. Load Data
```{r}
#setwd("~/Documents/好好学习！/R/ST309/st309-project")
library(tidyverse)
library(car)
library(ggplot2)
library(readxl)
library(stringr)
library(rgdal)


listings1 <- read_excel("9Dec2019_PriceAmenitiesRatings.xlsx")
listings_o <- read_excel("9Dec2019_PriceAmenitiesRatings.xlsx")
summary(listings1)

```

## 2. Price
```{r}

# Standardise all cleaning_fee such that entries with "NA" are 0 
listings1$cleaning_fee[is.na(listings1$cleaning_fee)]=0

# Add a new column with normalised prices (pro-rata per person for a 3-day stay)
# this is to account for the cleaning_fee, which can be substantial
listings1$price_n <- with(listings1,(price*3 + cleaning_fee)/3/guests_included)



```

## 3. host_since
```{r}
#host_since 
host_since_n <- listings1$host_since

#change host_since to years of operating, round up/down to nearest year
host_since_n <- as.numeric(round((as.Date("2020-02-08", format = "%Y-%m-%d") - as.Date(host_since_n, format = "%Y-%m-%d"))/365))

listings1$host_since_n <- host_since_n
```

## 4. host_response_time
```{r}
host_response_time_n <- as.factor(listings1$host_response_time)
#combine NA and N/A as N/A because this level might be significant in further analysis.
host_response_time_n[is.na(host_response_time_n)] <- "N/A"
listings1$host_response_time_n <- host_response_time_n
```

## 5. host_response_rate
```{r}
host_response_rate_n <- as.numeric(listings1$host_response_rate)
hist(host_response_rate_n)
summary(host_response_rate_n)
#recode the variable as factor: 100% is one level, not 100% another, NA the third
host_response_rate_n[host_response_rate_n != 1] <- "Not100"
host_response_rate_n[host_response_rate_n == 1] <- "100"
host_response_rate_n[is.na(host_response_rate_n)] <- "N/A"
host_response_rate_n <- as.factor(host_response_rate_n)
listings1$host_response_rate_n <- host_response_rate_n
```

## 6. host_is_superhost
```{r}
summary(as.factor(listings1$host_is_superhost))
#note that host_response_time has 944 NA, host_response_rate has 944 NA, host_is_superhost has 944 NA, investigation below
```

## 7. 944 entries w zero data for host

```{r}
#investigate:
compare_1 <- listings_o$id[is.na(listings_o$host_response_time)] == listings_o$id[is.na(listings_o$host_response_rate)]
length(compare_1[compare_1 == FALSE])
compare_2 <- listings_o$id[is.na(listings_o$host_response_rate)] == listings_o$id[is.na(listings_o$host_is_superhost)]
length(compare_2[compare_2 == FALSE])
#it is the same listings which has NA for all three columns
host_NA.dat <- subset(listings_o, is.na(host_response_rate))
head(host_NA.dat)
sample(host_NA.dat$id, size =3)
#remove the 944 entries
listings1 <- listings1[!is.na(listings1$host_since),]

```

By randomly checking five of the listings, the information about host is actually available on Airbnb. We believe the NA in the dataset might be due to some technical issues. Removing them from the dataset will not introduce significant bias. 

## 8. host verification

```{r}
host_vn <- listings1$host_verifications

#convert empty entry in host_verification to NA & save NA rows numbers
NArows <- c()
for (i in 1:length(host_vn)) {
  if (host_vn[i] == "[]") {
    host_vn[i] = NA
    NArows <- c(NArows, i)
  }
}

#split word entries in the host_verification
host_vnList <- strsplit(host_vn, split =",")

#clean host_vn by removing the signs 
remove.sign <- function (df) {
  str_replace_all(df, "[^[:alnum:]]", "")
  }
host_vnClean <- lapply(host_vnList, remove.sign)

#code the name of each list in the list of lists using their rownumber
names(host_vnClean) <- 1:length(host_vnClean)
#this is a precaution to deal with messed up row numbers after removing NAs

#get a list of all possible methods
getAllMethods <- function (LOL) {
  methods <- c()
  checks <- c()
  for (i in 1:length(LOL)) {
    for (j in 1:length(LOL[[i]])) {
      if (!(LOL[[i]][j] %in% methods)) {
        methods <- c(methods, LOL[[i]][j])
      }
    }
  }
  return(methods)
}

#NA is removed from the verification methods list
methods <- getAllMethods(host_vnClean)[1:20]


#take each method as a dimension, recode host_vnClean to a list of vectors
host_vnNew = matrix(0, ncol = length(methods),nrow = length(host_vnClean))
colnames(host_vnNew) <- methods

for (i in 1:length(host_vnClean)) {
  for (m in 1:length(methods)) {
    if (methods[m] %in% host_vnClean[[i]]) {
      host_vnNew[i,m] <- 1
    }
  }
}

#perform kmeans clustering
km.out <- kmeans(host_vnNew, 4, nstart = 100)
kmeans_results <- km.out$cluster
kmeans_centroids <- km.out$centers
for (i in 1:4) {print(length(which(cluster_results == i)))}

listings1$host_verification_n <- kmeans_results
```

## 9. street

```{r}
street_n <- as.factor(listings1$street)
summary(street_n)
#many do not have an exact street name, not considered further.
```

## 10. neighbourhood_cleansed

```{r}
neig_n <- as.factor(listings1$neighbourhood_cleansed)
summary(neig_n)
# no interesting transformation to think of
```

## 11. latitude and longitude

```{r}
location <- listings1[c("zipcode", "latitude", "longitude")]
summary(location)
min(location$latitude) #bottom = 51.29479 
max(location$latitude) #top = 51.68169
min(location$longitude) #left = -0.4966
max(location$longitude) #right = 0.285

london_wards <- readOGR(dsn = "London-wards/London_Ward.shp")
london_wards_f <- fortify(london_wards)   
london_wards$id <- row.names(london_wards)  
head(london_wards_f)
ggplot(london_wards_f, aes(long, lat, group = group)) + geom_polygon()
```


# II. Data Analysis